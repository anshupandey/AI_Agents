{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/AI_Agents/blob/main/AAP_C4_Getting_started_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "359697d5",
      "metadata": {
        "id": "359697d5"
      },
      "source": [
        "# LangChain Cookbook üë®‚Äçüç≥üë©‚Äçüç≥"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d788b0",
      "metadata": {
        "id": "11d788b0"
      },
      "source": [
        "\n",
        "\n",
        "### **What is LangChain?**\n",
        "> LangChain is a framework for developing applications powered by language models.\n",
        "\n",
        " LangChain makes the complicated parts of working & building with AI models easier. It helps do this in two ways:\n",
        "\n",
        "1. **Integration** - Bring external data, such as your files, other applications, and api data, to your LLMs\n",
        "2. **Agency** - Allow your LLMs to interact with it's environment via decision making. Use LLMs to help decide which action to take next\n",
        "\n",
        "### **Why LangChain?**\n",
        "1. **Components** - LangChain makes it easy to swap out abstractions and components necessary to work with language models.\n",
        "\n",
        "2. **Customized Chains** - LangChain provides out of the box support for using and customizing 'chains' - a series of actions strung together.\n",
        "\n",
        "3. **Speed üö¢** - This team ships insanely fast. You'll be up to date with the latest LLM features.\n",
        "\n",
        "4. **Community üë•** - Wonderful discord and community support, meet ups, hackathons, etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "tags": [],
        "id": "ad3fc543-8dc7-43da-b095-0e4a965b7de4"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet google-cloud-aiplatform requests\n",
        "!pip install -q -U langchain-google-vertexai langchain-core\n",
        "!pip install wikipedia langchain-community langchain-openai langchain-together --quiet --user"
      ],
      "id": "ad3fc543-8dc7-43da-b095-0e4a965b7de4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c810968-005f-4776-8d2b-99e04a49b550"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ],
      "id": "5c810968-005f-4776-8d2b-99e04a49b550"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1e0edafe-5cf9-4979-87fa-79958402f9dc",
        "outputId": "8da4456f-41f7-41c4-ce0b-48f2bf6ec907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "id": "1e0edafe-5cf9-4979-87fa-79958402f9dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b27adccc-967a-469c-a05e-5a1eabaef1a3"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>‚ö†Ô∏è The kernel is going to restart. Please wait until it is finished before continuing to the next step. ‚ö†Ô∏è</b>\n",
        "</div>"
      ],
      "id": "b27adccc-967a-469c-a05e-5a1eabaef1a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "299649d4-7959-455a-8971-d0d3bb5cc474"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ],
      "id": "299649d4-7959-455a-8971-d0d3bb5cc474"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e641fb7d-2ed9-492e-ba8e-fabc86721630"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "id": "e641fb7d-2ed9-492e-ba8e-fabc86721630"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95c810db-eeea-4475-8c03-9016429272f8"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "id": "95c810db-eeea-4475-8c03-9016429272f8"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "529b3f2d-c270-4937-9b70-16651f260125"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"jrproject-402905\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "id": "529b3f2d-c270-4937-9b70-16651f260125"
    },
    {
      "cell_type": "markdown",
      "id": "05bb564d",
      "metadata": {
        "id": "05bb564d"
      },
      "source": [
        "# LangChain Components\n",
        "\n",
        "## Schema - Nuts and Bolts of working with Large Language Models (LLMs)\n",
        "\n",
        "### **Text**\n",
        "The natural language way to interact with LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8e0dc06c",
      "metadata": {
        "hide_input": false,
        "id": "8e0dc06c",
        "outputId": "ccfbc95f-6adc-4fcd-8917-c29264e8d4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What day comes after Friday?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# You'll be working with simple strings (that'll soon grow in complexity!)\n",
        "my_text = \"What day comes after Friday?\"\n",
        "my_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f39eb39",
      "metadata": {
        "id": "2f39eb39"
      },
      "source": [
        "### **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with\n",
        "\n",
        "For more, see OpenAI's [documentation](https://platform.openai.com/docs/guides/chat/introduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "99b0935b",
      "metadata": {
        "id": "99b0935b"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "model = ChatVertexAI(model=\"gemini-1.5-flash-001\",temperature=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d2f7af",
      "metadata": {
        "id": "a2d2f7af"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ],
      "metadata": {
        "id": "EwtBhoEPmteV",
        "outputId": "4459be52-2532-4f37-e3ed-bb07630ab3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EwtBhoEPmteV",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Ciao! \\n', response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 9, 'candidates_token_count': 4, 'total_token_count': 13}}, id='run-70b22946-8ce9-4083-8b31-0228dc5a8c84-0', usage_metadata={'input_tokens': 9, 'output_tokens': 4, 'total_tokens': 13})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(messages).content"
      ],
      "metadata": {
        "id": "F4LFfg-anFYN",
        "outputId": "8fbe3c7a-e203-4ad7-a644-f97fa78a508c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "F4LFfg-anFYN",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ciao! \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "878d6a36",
      "metadata": {
        "id": "878d6a36",
        "outputId": "e69322ed-5956-4fcd-d7ee-17ea54379095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Try a fresh tomato salad with mozzarella and basil! üçÖ \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "messages = [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "    ]\n",
        "\n",
        "model.invoke(messages).content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a425aaa",
      "metadata": {
        "id": "0a425aaa"
      },
      "source": [
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8fd3fe88",
      "metadata": {
        "id": "8fd3fe88",
        "outputId": "5e7ab19e-d912-40de-cfb6-52bd1b014221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You could visit the Promenade des Anglais, a famous seaside walkway. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ").content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5ee37a",
      "metadata": {
        "id": "ff5ee37a"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "238a49f6",
      "metadata": {
        "id": "238a49f6",
        "outputId": "85cb15f1-e2ae-4852-da12-72b143e447c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Friday \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ").content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Models**\n",
        "\n",
        "#### **ChatModels**"
      ],
      "metadata": {
        "id": "zANJcYEr0H5v"
      },
      "id": "zANJcYEr0H5v"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-together langchain-openai --quiet"
      ],
      "metadata": {
        "id": "Xd6jktDY0hAp"
      },
      "id": "Xd6jktDY0hAp",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vertex AI: Gemini 1.5 Flash\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "model = ChatVertexAI(model=\"gemini-1.5-flash-001\",temperature=0.5)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dr0HBZfG0RsP",
        "outputId": "b6302b44-72f3-4e83-975c-64b547744d27"
      },
      "id": "dr0HBZfG0RsP",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ciao! \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_together import ChatTogether\n",
        "together_api = \"xxxxxxxxxxxxxxxxxxx\"\n",
        "model = ChatTogether(model=\"meta-llama/Llama-3-8b-chat-hf\",temperature=0.5,together_api_key=together_api)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xsC5hnI00bF-",
        "outputId": "fa1a714d-aaba-46ee-a180-1244a9c0c43a"
      },
      "id": "xsC5hnI00bF-",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ciao!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "openai_key=\"sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0.5,openai_api_key=openai_key)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vpyTOlk21Mba",
        "outputId": "22081874-a548-439d-f84b-5f54cc97d3f1"
      },
      "id": "vpyTOlk21Mba",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ciao!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LLMs**"
      ],
      "metadata": {
        "id": "KgBgFW-M7_Ya"
      },
      "id": "KgBgFW-M7_Ya"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "# To use model\n",
        "model = VertexAI(model_name=\"gemini-1.5-flash-001\")\n",
        "\n",
        "# I like to use three double quotation marks for my prompts because it's easier to read\n",
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n",
        "\n",
        "print(model(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Hzwxvw8B5I",
        "outputId": "04148007-e203-4f3e-e6ae-4dafa0d5c2f0"
      },
      "id": "a0Hzwxvw8B5I",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The statement is wrong because **tomorrow after Monday is Tuesday, not Wednesday**. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "openai_key=\"sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "model = OpenAI(openai_api_key=openai_key,model='gpt-3.5-turbo-instruct',temperature=0.5)\n",
        "\n",
        "# I like to use three double quotation marks for my prompts because it's easier to read\n",
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n",
        "\n",
        "print(model(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ARnVw88JvJ",
        "outputId": "3d26e31c-4687-4f54-c56c-c7cd08e72fc0"
      },
      "id": "57ARnVw88JvJ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The statement is incorrect because it skips over Tuesday, making it seem like Tuesday does not exist. The correct statement would be \"Today is Monday, tomorrow is Tuesday.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OutputParsers**\n",
        "\n",
        "Notice that the response from the model is an AIMessage. This contains a string response along with other metadata about the response. Oftentimes we may just want to work with the string response. We can parse out just this response by using a simple output parser.\n",
        "\n",
        "\n",
        "We first import the simple output parser."
      ],
      "metadata": {
        "id": "-xqSew0toV-i"
      },
      "id": "-xqSew0toV-i"
    },
    {
      "cell_type": "code",
      "source": [
        "# Vertex AI: Gemini 1.5 Flash\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "model = ChatVertexAI(model=\"gemini-1.5-flash-001\",temperature=0.5)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]"
      ],
      "metadata": {
        "id": "AHUb4H8K_C8K"
      },
      "id": "AHUb4H8K_C8K",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.invoke(messages)\n",
        "result"
      ],
      "metadata": {
        "id": "BhcLwVr7nzaI",
        "outputId": "515c2057-cd7a-4f7c-d1c8-3b5348641b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BhcLwVr7nzaI",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Ciao! \\n', response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 9, 'candidates_token_count': 4, 'total_token_count': 13}}, id='run-083ea69f-697f-43e1-bfbb-203dc8aa5afe-0', usage_metadata={'input_tokens': 9, 'output_tokens': 4, 'total_tokens': 13})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "m8S7oeTtntr5"
      },
      "id": "m8S7oeTtntr5",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser.invoke(result)"
      ],
      "metadata": {
        "id": "MV4GZnAioPOU",
        "outputId": "a47eb332-5ad4-4346-d134-173933442900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "MV4GZnAioPOU",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ciao! \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66bf9634",
      "metadata": {
        "id": "66bf9634"
      },
      "source": [
        "### **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-core --quiet"
      ],
      "metadata": {
        "id": "ops6NOQtAhyI"
      },
      "id": "ops6NOQtAhyI",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3bbf58b2",
      "metadata": {
        "id": "3bbf58b2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6ad9bef6",
      "metadata": {
        "id": "6ad9bef6",
        "outputId": "b8f4e4dd-2e0e-4d98-87c7-4c6a1cc41678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'my_document_id': 234234, 'my_document_source': 'The LangChain Papers', 'my_document_create_time': 1680013019}, page_content=\"This is my document. It is full of text that I've gathered from other places\")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd19754",
      "metadata": {
        "id": "3bd19754"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0798d3ca",
      "metadata": {
        "id": "0798d3ca",
        "outputId": "15b4c7f4-1a5f-4fe0-9dc4-8dd1ebee28a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c38fe99f",
      "metadata": {
        "id": "c38fe99f"
      },
      "source": [
        "## Prompts - Text generally used as instructions to your model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b9318ed",
      "metadata": {
        "id": "8b9318ed"
      },
      "source": [
        "### **Prompt**\n",
        "What you'll pass to the underlying model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2d270239",
      "metadata": {
        "id": "2d270239",
        "outputId": "c6d916c3-e9f4-4297-d63f-ef7b732c4c9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The statement is wrong because **tomorrow after Monday is Tuesday, not Wednesday**. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "# To use model\n",
        "model = VertexAI(model_name=\"gemini-1.5-flash-001\")\n",
        "\n",
        "# I like to use three double quotation marks for my prompts because it's easier to read\n",
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n",
        "\n",
        "print(model(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74988254",
      "metadata": {
        "id": "74988254"
      },
      "source": [
        "### **Prompt Template**\n",
        "An object that helps create prompts based on a combination of user input, other non-static information and a fixed template string.\n",
        "\n",
        "Think of it as an [f-string](https://realpython.com/python-f-strings/) in python but for prompts\n",
        "\n",
        "*Advanced: Check out LangSmithHub(https://smith.langchain.com/hub) for many more communit prompt templates*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "abcc212d",
      "metadata": {
        "id": "abcc212d",
        "outputId": "4eab14f7-6e1b-4712-cdea-224352067fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['language', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='Translate the following into {language}:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following into {language}:\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
        "result"
      ],
      "metadata": {
        "id": "n_rf4WC4ywMB",
        "outputId": "3ac429bf-c0b8-42cf-8a00-2580bfaf1a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n_rf4WC4ywMB",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='hi')])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_messages()"
      ],
      "metadata": {
        "id": "1zdi7pxqrK-L",
        "outputId": "78ee1e30-941d-46d4-cf14-ff2b4da7623e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1zdi7pxqrK-L",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following into italian:'),\n",
              " HumanMessage(content='hi')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29fc79c",
      "metadata": {
        "id": "f29fc79c"
      },
      "source": [
        "## Chains ‚õìÔ∏è‚õìÔ∏è‚õìÔ∏è\n",
        "Combining different LLM calls and action automatically\n",
        "\n",
        "Ex: Summary #1, Summary #2, Summary #3 > Final Summary\n",
        "\n",
        "Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo&t=2s) explaining different summarization chain types\n",
        "\n",
        "There are [many applications of chains](https://python.langchain.com/en/latest/modules/chains/how_to_guides.html) search to see which are best for your use case.\n",
        "\n",
        "We'll cover two of them:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34ba415",
      "metadata": {
        "id": "c34ba415"
      },
      "source": [
        "### 1. Simple Sequential Chains\n",
        "\n",
        "Easy chains where you can use the output of an LLM as an input into another. Good for breaking up tasks (and keeping your LLM focused)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "79fc0950",
      "metadata": {
        "id": "79fc0950"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "model = ChatVertexAI(model=\"gemini-1.5-flash-001\",temperature=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "M1kKg2fvvqsj"
      },
      "id": "M1kKg2fvvqsj",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "system_template = \"Translate the following into {language}:\"\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "id": "IFly8IBave3A",
        "outputId": "2bf1f464-911d-4f67-f44f-beb9b2d6d0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IFly8IBave3A",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['language', 'text'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='Translate the following into {language}:')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "43d4494a",
      "metadata": {
        "id": "43d4494a",
        "outputId": "15032de1-ec41-460f-a315-e192f151eab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ciao! \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# implementing a chain with LangChain\n",
        "chain = prompt_template | model | parser\n",
        "\n",
        "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_output(text):\n",
        "  return {\"Translation\":text}"
      ],
      "metadata": {
        "id": "kDQuOaMr1CXo"
      },
      "id": "kDQuOaMr1CXo",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = prompt_template | model | parser | format_output\n",
        "\n",
        "chain2.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
      ],
      "metadata": {
        "id": "_7KgQwcx1FvZ",
        "outputId": "e5a2817e-c6ec-46df-be05-9c65d827de38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_7KgQwcx1FvZ",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Translation': 'Ciao! \\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. JSON Q&A Chain"
      ],
      "metadata": {
        "id": "y-3BN6srFgc9"
      },
      "id": "y-3BN6srFgc9"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "model = ChatVertexAI(model=\"gemini-1.5-flash-001\",temperature=0.5,\n",
        "                     model_kwargs={\"response_format\": {\"type\":\"json_object\"}})"
      ],
      "metadata": {
        "id": "dziE4vr8EaP3"
      },
      "id": "dziE4vr8EaP3",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"Answer the question to the best of your ability with factual content.\"\n",
        "    \"You must always output a JSON object with an 'answer' key and a 'followup_question' Key.\"\n",
        "    \"{question}\")\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuCIG2tyF6lD",
        "outputId": "9b6d38ae-34af-4eab-a2c6-44954c7dd0c0"
      },
      "id": "iuCIG2tyF6lD",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"Answer the question to the best of your ability with factual content.You must always output a JSON object with an 'answer' key and a 'followup_question' Key.{question}\"))])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "parser = SimpleJsonOutputParser()"
      ],
      "metadata": {
        "id": "r8VIjOvzG364"
      },
      "id": "r8VIjOvzG364",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template | model | parser\n",
        "\n",
        "chain.invoke({\"question\": \"What is Artificial Intelligence?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpHh3XxnGgUC",
        "outputId": "3d3b0cf8-38c6-4bae-d0ca-be0e4db4f662"
      },
      "id": "jpHh3XxnGgUC",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Artificial intelligence (AI) is the simulation of human intelligence processes by computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction. AI research has been highly successful in developing effective techniques for solving a wide range of problems, from game playing to medical diagnosis.',\n",
              " 'followup_question': 'What are some examples of AI in everyday life?'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Extended Chain"
      ],
      "metadata": {
        "id": "xTnVGyBXIqwZ"
      },
      "id": "xTnVGyBXIqwZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "model = ChatVertexAI(model=\"gemini-1.5-flash-001\",temperature=0.5)"
      ],
      "metadata": {
        "id": "1X6R3uvDGtzG"
      },
      "id": "1X6R3uvDGtzG",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "joke_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a joke about {topic}\")\n",
        "joke_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ks1MMKJXMJ",
        "outputId": "9728877e-7839-4de7-e2d5-46af96192877"
      },
      "id": "K0ks1MMKJXMJ",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Tell me a joke about {topic}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = joke_prompt | model | parser\n",
        "chain1.invoke({\"topic\": \"cats\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "groeoLMFJjIw",
        "outputId": "df399fa7-4f2f-49ba-9dd5-c85898d288bb"
      },
      "id": "groeoLMFJjIw",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the cat get a job at the library? \\n\\nBecause he was a real bookworm! üìöüê± \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_prompt = ChatPromptTemplate.from_template(\"Is this a funny joke? {joke}  \")\n",
        "analyze_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6MF_Iy-JpK5",
        "outputId": "5f21a85b-d200-407f-9e6d-3adff385baf8"
      },
      "id": "x6MF_Iy-JpK5",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['joke'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['joke'], template='Is this a funny joke? {joke}  '))])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_output(joke):\n",
        "  print(\"Joke: \",joke)\n",
        "  print(\"-------------------\")\n",
        "  return {\"joke\":joke}"
      ],
      "metadata": {
        "id": "n7IHbb_8KSQx"
      },
      "id": "n7IHbb_8KSQx",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extended_chain = chain1 | format_output | analyze_prompt | model | parser\n",
        "extended_chain.invoke({\"topic\": \"cats\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "2IBMUHeDJ8tX",
        "outputId": "41af2975-0c9b-469e-be27-5ab2c65a72cc"
      },
      "id": "2IBMUHeDJ8tX",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joke:  Why did the cat get a job at the library?\n",
            "\n",
            "Because he was a real bookworm! üìöüòπ \n",
            "\n",
            "-------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, that\\'s a funny joke! It\\'s a classic pun that plays on the double meaning of \"bookworm\". \\n\\nHere\\'s why it works:\\n\\n* **Wordplay:** The joke uses the word \"bookworm\" in two ways:\\n    * Literally, as a creature that eats books.\\n    * Figuratively, as someone who loves to read.\\n* **Unexpected Twist:** The listener expects the joke to be about a cat\\'s love of reading, but the punchline reveals a more literal interpretation, making it humorous.\\n* **Simple and Relatable:**  The joke is easy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain = joke_prompt | model | parser | format_output | analyze_prompt | model | parser\n",
        "main_chain.invoke({\"topic\": \"cats\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "PETlG-upKg1U",
        "outputId": "8f9a6556-0e81-42cd-d723-3592df1f4c8b"
      },
      "id": "PETlG-upKg1U",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, that\\'s a funny joke! It\\'s a classic pun using the phrase \"bookworm\" in two ways:\\n\\n* **Literally:**  A person who loves to read.\\n* **Figuratively:**  A worm that eats books (which is what cats are known to do sometimes!). \\n\\nThe humor comes from the unexpected connection between the two meanings and the playful image of a cat working in a library. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tools**"
      ],
      "metadata": {
        "id": "VzBxMeaHN5Cy"
      },
      "id": "VzBxMeaHN5Cy"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "wikipedia_api = WikipediaAPIWrapper(top_k_results=1, language=\"en\", doc_content_chars_max=2000)\n",
        "tool = WikipediaQueryRun(api_wrapper=wikipedia_api)"
      ],
      "metadata": {
        "id": "TsBPKowCOBWd"
      },
      "id": "TsBPKowCOBWd",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool.invoke(\"Artificial Intelligence?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "n_MnWdhwOkTB",
        "outputId": "9741d486-6ce5-493c-d57b-ba1b3e418844"
      },
      "id": "n_MnWdhwOkTB",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nSome high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, Apple Intelligence, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nAlan Turing was the first person to conduct substantial research in the field that he called machine intelligence. Artificial intelligence was founded as an academic discipline in 1956, by those now considered the founding fathers of AI, John McCarthy, Marvin Minksy, Nathaniel Rochester, and Claude Shannon. The field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\\nThe growing use of artificial intelligence in the 21st century is influencing a societal and economic sh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tool.name)\n",
        "print(tool.description)\n",
        "print(tool.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxEP6UzyPEgv",
        "outputId": "b0f1dcf9-482c-4960-9e8e-1a199951928b"
      },
      "id": "XxEP6UzyPEgv",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wikipedia\n",
            "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
            "{'query': {'title': 'Query', 'description': 'query to look up on wikipedia', 'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "model = ChatVertexAI(model=\"gemini-1.5-flash-001\",temperature=0.5)"
      ],
      "metadata": {
        "id": "IXXlAlYBPoTq"
      },
      "execution_count": 60,
      "outputs": [],
      "id": "IXXlAlYBPoTq"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "search_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Generate only one keyword to be searched over wikipedia for the topic: {topic}\")\n",
        "search_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918e279f-f902-48c8-e587-61e9e8a789d3",
        "id": "o3jbExNKPoTr"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Generate only one keyword to be searched over wikipedia for the topic: {topic}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "id": "o3jbExNKPoTr"
    },
    {
      "cell_type": "code",
      "source": [
        "def format_output(topic):\n",
        "  print(\"Topic proposed: \",topic)\n",
        "  return topic.strip()"
      ],
      "metadata": {
        "id": "9SkIRNeNSO_U"
      },
      "id": "9SkIRNeNSO_U",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = search_prompt | model | parser  | tool | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "4_bvIQ2EQFjA",
        "outputId": "212567e1-2f05-4b6e-d311-474e0e9be1b1"
      },
      "id": "4_bvIQ2EQFjA",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nSome high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, Apple Intelligence, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nAlan Turing was the first person to conduct substantial research in the field that he called machine intelligence. Artificial intelligence was founded as an academic discipline in 1956, by those now considered the founding fathers of AI, John McCarthy, Marvin Minksy, Nathaniel Rochester, and Claude Shannon. The field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\\nThe growing use of artificial intelligence in the 21st century is influencing a societal and economic sh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = search_prompt | model | parser | format_output  | tool | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ],
      "metadata": {
        "id": "fgwnLXXJQV8p",
        "outputId": "ac5dd4f4-eda1-4960-cb27-6ef198267ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "id": "fgwnLXXJQV8p",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic proposed:  Artificial intelligence \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nSome high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, Apple Intelligence, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nAlan Turing was the first person to conduct substantial research in the field that he called machine intelligence. Artificial intelligence was founded as an academic discipline in 1956, by those now considered the founding fathers of AI, John McCarthy, Marvin Minksy, Nathaniel Rochester, and Claude Shannon. The field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\\nThe growing use of artificial intelligence in the 21st century is influencing a societal and economic sh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the attached information in two lines: {content}\")\n",
        "summarize_prompt"
      ],
      "metadata": {
        "id": "3TyTMYk-EVuy",
        "outputId": "46f86241-6827-48a3-9495-5d8b8a0473d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3TyTMYk-EVuy",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['content'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['content'], template='Summarize the attached information in two lines: {content}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_wiki(content):\n",
        "  print(\"Content: \",content)\n",
        "  print(\"-------------------\")\n",
        "  return {\"content\":content.strip()}"
      ],
      "metadata": {
        "id": "wmlT0iFDGuwx"
      },
      "id": "wmlT0iFDGuwx",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = search_prompt | model | parser | format_output  | tool | parser | format_wiki | summarize_prompt | model | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ],
      "metadata": {
        "id": "r0Mtc4vLGodx",
        "outputId": "754eafc0-2262-4923-964f-076bb609658f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "id": "r0Mtc4vLGodx",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-flash. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic proposed:  Artificial intelligence \n",
            "\n",
            "Content:  Page: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
            "Some high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, Apple Intelligence, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Alan Turing was the first person to conduct substantial research in the field that he called machine intelligence. Artificial intelligence was founded as an academic discipline in 1956, by those now considered the founding fathers of AI, John McCarthy, Marvin Minksy, Nathaniel Rochester, and Claude Shannon. The field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\n",
            "The growing use of artificial intelligence in the 21st century is influencing a societal and economic sh\n",
            "-------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial intelligence (AI) is the study of machines exhibiting intelligence, enabling them to perceive, learn, and act to achieve goals. This field has experienced periods of boom and bust, but recent advancements in deep learning have led to a resurgence of interest and significant progress in AI applications across various sectors. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkm_-p82G8L-"
      },
      "id": "bkm_-p82G8L-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}