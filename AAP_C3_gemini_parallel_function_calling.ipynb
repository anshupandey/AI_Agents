{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/AI_Agents/blob/main/AAP_C3_gemini_parallel_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Parallel Function Calls and Multiple Function Responses in Gemini"
      ],
      "metadata": {
        "id": "gbCxadJVx88B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Gemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases. The Gemini API gives you access to the Gemini Pro and Gemini Pro Vision models.\n",
        "\n",
        "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets you create a description of a function in your code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "In this tutorial, you'll learn how to work with parallel function calling within Gemini Function Calling, including:\n",
        "    \n",
        "- Handling parallel function calls for repeated functions\n",
        "- Working with parallel function calls across multiple functions\n",
        "- Extracting multiple function calls from a Gemini response\n",
        "- Calling multiple functions and returning them to Gemini\n",
        "\n",
        "### What is parallel function calling?\n",
        "\n",
        "In previous versions of the Gemini Pro models (prior to May 2024), Gemini would return two or more chained function calls if the model determined that more than one function call was needed before returning a natural language summary. Here, a chained function call means that you get the first function call response, return the API data to Gemini, get a second function call response, return the API data to Gemini, and so on.\n",
        "\n",
        "In recent versions of specific Gemini Pro models (from May 2024 and on), Gemini has the ability to return two or more function calls in parallel (i.e., two or more function call responses within the first function call response object). Parallel function calling allows you to fan out and parallelize your API calls or other actions that you perform in your application code, so you don't have to work through each function call response and return one-by-one! Refer to the [Gemini Function Calling documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) for more information on which Gemini model versions support parallel function calling.\n",
        "\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/function-calling/parallel-function-calling-in-gemini.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "tags": [],
        "outputId": "5a4509dc-bf24-431c-ae54-a9cc5edbe035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade --user --quiet google-cloud-aiplatform wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e5f1bc-11ae-4d94-d9e4-c82c3ed293a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"jrproject-402905\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "## Code Examples\n",
        "\n",
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lslYAvw37JGQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "from IPython.display import display, Markdown\n",
        "from typing import List, Dict\n",
        "from vertexai.generative_models import (\n",
        "    FunctionDeclaration,\n",
        "    GenerativeModel,\n",
        "    GenerationConfig,\n",
        "    GenerationResponse,\n",
        "    Part,\n",
        "    Tool,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o77Xl_JDjvYf"
      },
      "source": [
        "### Define helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si8oe70kjvYf"
      },
      "outputs": [],
      "source": [
        "# Helper function to extract one or more function calls from a Gemini Function Call response\n",
        "def extract_function_calls(response: GenerationResponse) -> List[Dict]:\n",
        "    function_calls = []\n",
        "    if response.candidates[0].function_calls:\n",
        "        for function_call in response.candidates[0].function_calls:\n",
        "            function_call_dict = {function_call.name: {}}\n",
        "            for key, value in function_call.args.items():\n",
        "                function_call_dict[function_call.name][key] = value\n",
        "            function_calls.append(function_call_dict)\n",
        "    return function_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3KHAr6BsJY6"
      },
      "source": [
        "## Example: Parallel function calls on the same function\n",
        "\n",
        "A great use case for parallel function calling is when you have a function that only accepts one parameter per API call and you need to make repeated calls to that function.\n",
        "\n",
        "With Parallel Function Calling, rather than having to send N number of API requests to Gemini for N number function calls, instead you can send a single API request to Gemini, receive N number of Function Call Responses within a single response, make N number of external API calls in your code, then return all of the API responses to Gemini in bulk. And you can do all of this without any extra configuration in your function declarations, tools, or requests to Gemini.\n",
        "\n",
        "In this example, you'll do exactly that and use Parallel Function Calling in Gemini to ask about multiple topics on [Wikipedia](https://www.wikipedia.org/). Let's get started!\n",
        "\n",
        "### Write function declarations and wrap them in a tool\n",
        "\n",
        "First, define your function declarations and tool using the Vertex AI Python SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bu0vJhbjvYf"
      },
      "outputs": [],
      "source": [
        "search_wikipedia = FunctionDeclaration(\n",
        "    name=\"search_wikipedia\",\n",
        "    description=\"Search for articles on Wikipedia\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Query to search for on Wikipedia\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "wikipedia_tool = Tool(\n",
        "    function_declarations=[\n",
        "        search_wikipedia,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqsoXcGQjvYg"
      },
      "source": [
        "### Initialize the Gemini model\n",
        "\n",
        "Now you can initialize Gemini using a [model version that supports parallel function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6kyutg2jvYg"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\n",
        "    \"gemini-1.5-pro-001\",\n",
        "    generation_config=GenerationConfig(temperature=0),\n",
        "    tools=[wikipedia_tool],\n",
        ")\n",
        "chat = model.start_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dfC_hDsjvYg"
      },
      "source": [
        "### Send prompt to Gemini\n",
        "\n",
        "Send a prompt to Gemini that includes a phrase that you expect to invoke two or more function calls.\n",
        "\n",
        "In this case we'll ask about three different article topics to search for on Wikipedia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD4UJ6BcsJY6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "prompt = \"Search for articles related to solar panels, renewable energy, and battery storage and provide a summary of your findings\"\n",
        "\n",
        "response = chat.send_message(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2bQZglFjvYh"
      },
      "source": [
        "### Extract function names and parameters\n",
        "\n",
        "Use the helper function that we created earlier to extract the function names and function parameters for each Function Call that Gemini responded with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkO5UJSIjvYh",
        "outputId": "0328bf98-63a7-4f86-88a9-076cabbd7163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'search_wikipedia': {'query': 'Solar panels'}},\n",
              " {'search_wikipedia': {'query': 'Renewable energy'}},\n",
              " {'search_wikipedia': {'query': 'Battery storage'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "function_calls = extract_function_calls(response)\n",
        "function_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUTjzE-kjvYi"
      },
      "source": [
        "Note that the helper function is just one way to extract fields from the structured Function Call response. You can modify the helper function or write your own custom code to extract and get the fields into your preferred format or data structure!\n",
        "\n",
        "### Make external API calls\n",
        "\n",
        "Next, you'll loop through the Function Calls and use the `wikipedia` Python package to make an API call for each search query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fSBTa0QjvYj",
        "outputId": "3d896f5a-8088-45c8-f3ad-d28aa4c37556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'search_wikipedia': {'query': 'Solar panels'}}\n",
            "{'search_wikipedia': {'query': 'Renewable energy'}}\n",
            "{'search_wikipedia': {'query': 'Battery storage'}}\n"
          ]
        }
      ],
      "source": [
        "api_response = []\n",
        "\n",
        "# Loop over multiple function calls\n",
        "for function_call in function_calls:\n",
        "    print(function_call)\n",
        "\n",
        "    # Make external API call\n",
        "    result = wikipedia.summary(function_call[\"search_wikipedia\"][\"query\"])\n",
        "\n",
        "    # Collect all API responses\n",
        "    api_response.append(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiuO6UXfjvYj"
      },
      "source": [
        "### Get a natural language summary\n",
        "\n",
        "Now you can return all of the API responses to Gemini so that it can generate a natural language summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "SXlwZ2BRjvYk",
        "outputId": "113057c2-68b5-4d9c-9ed5-e7a8efaa7166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Solar panels convert sunlight into electricity using photovoltaic cells, offering a renewable and clean energy source that can reduce greenhouse gas emissions and lower electricity bills. However, they depend on sunlight availability, require cleaning, and have high initial costs. \n\nRenewable energy, including solar, wind, and hydropower, is replenished naturally and has become increasingly efficient and cheaper. It's vital for combating climate change by reducing greenhouse gas emissions compared to fossil fuels. While facing obstacles like fossil fuel subsidies and land use concerns, the transition to renewables is crucial for a sustainable future.\n\nBattery storage power stations are essential for stabilizing electric grids by storing energy from sources like solar and wind power. They provide rapid response to grid fluctuations, ensuring reliability. While their capacity is smaller than pumped-storage hydropower, battery storage is rapidly growing and becoming more cost-effective, making it a key player in the transition to a cleaner and more resilient energy system. \n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Return the API response to Gemini\n",
        "\n",
        "function_responses = []\n",
        "for i in range(len(function_calls)):\n",
        "    function_responses.append(\n",
        "        Part.from_function_response(\n",
        "            name=\"search_wikipedia\",\n",
        "            response={\n",
        "                \"content\": api_response[i],\n",
        "            },\n",
        "        )\n",
        "    )\n",
        "\n",
        "response = chat.send_message(function_responses)\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R0h9boIjvYl"
      },
      "source": [
        "And you're done with no extra configuration necessary!\n",
        "\n",
        "Note that Gemini will use the information in your `FunctionDeclarations` to determine if and when it should return parallel Function Call responses, or it will determine which Function Calls need to be made before others to get information that a subsequent Function Call depends on. So be sure to account for this behavior in your logic and application code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riYC7Z-RjvYl"
      },
      "source": [
        "## Example: Parallel function calls across multiple functions\n",
        "\n",
        "Another good fit for parallel function calling is when you have multiple, independent functions that you want to be able to call in parallel, which reduces the number of consecutive Gemini API calls that you need to make and (ideally) reduces the overall response time to the end user who is waiting for a natural language response.\n",
        "\n",
        "In this example, you'll use Parallel Function Calling in Gemini to ask about multiple aspects of topics and articles on [Wikipedia](https://www.wikipedia.org/).\n",
        "\n",
        "### Write function declarations and wrap them in a tool\n",
        "\n",
        "First, define your function declarations and tool using the Vertex AI Python SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niPXM0mwjvYl"
      },
      "outputs": [],
      "source": [
        "search_wikipedia = FunctionDeclaration(\n",
        "    name=\"search_wikipedia\",\n",
        "    description=\"Search for articles on Wikipedia\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Query to search for on Wikipedia\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "suggest_wikipedia = FunctionDeclaration(\n",
        "    name=\"suggest_wikipedia\",\n",
        "    description=\"Get suggested titles from Wikipedia for a given term\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Query to search for suggested titles on Wikipedia\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "summarize_wikipedia = FunctionDeclaration(\n",
        "    name=\"summarize_wikipedia\",\n",
        "    description=\"Get article summaries from Wikipedia\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"topic\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Query to search for article summaries on Wikipedia\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "wikipedia_tool = Tool(\n",
        "    function_declarations=[\n",
        "        search_wikipedia,\n",
        "        suggest_wikipedia,\n",
        "        summarize_wikipedia,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xucoK52HjvYm"
      },
      "source": [
        "### Initialize the Gemini model\n",
        "\n",
        "Now you can initialize Gemini using a [model version that supports parallel function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h1cWIYtjvYm"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\n",
        "    \"gemini-1.5-pro-001\",\n",
        "    generation_config=GenerationConfig(temperature=0),\n",
        "    tools=[wikipedia_tool],\n",
        ")\n",
        "chat = model.start_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxx3OetljvYn"
      },
      "source": [
        "### Send prompt to Gemini\n",
        "\n",
        "Send a prompt to Gemini that includes a phrase that you expect to invoke two or more function calls.\n",
        "\n",
        "In this case we'll ask about three types of details to look up for a given topic on Wikipedia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "eCTv-fFOjvYn"
      },
      "outputs": [],
      "source": [
        "prompt = \"Show the search results, variations, and article summaries about Wikipedia articles related to the solar system\"\n",
        "\n",
        "response = chat.send_message(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mp8zaBhjvYo"
      },
      "source": [
        "### Extract function names and parameters\n",
        "\n",
        "Use the helper function that we created earlier to extract the function names and function parameters for each Function Call that Gemini responded with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT_ZDNjXjvYo",
        "outputId": "2f1a6336-a604-43ba-cb56-e68b4fb37535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'search_wikipedia': {'query': 'solar system'}},\n",
              " {'suggest_wikipedia': {'query': 'solar system'}},\n",
              " {'summarize_wikipedia': {'topic': 'solar system'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "function_calls = extract_function_calls(response)\n",
        "function_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgLqFRJsjvYy"
      },
      "source": [
        "### Make external API calls\n",
        "\n",
        "Next, you'll loop through the Function Calls and use the `wikipedia` Python package to make APIs calls and gather information from Wikipedia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrnQf3RcjvYz",
        "outputId": "3e7397fe-1f08-4265-aa9e-e7fd8b78aa96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'search_wikipedia': {'query': 'solar system'}}\n",
            "{'suggest_wikipedia': {'query': 'solar system'}}\n",
            "{'summarize_wikipedia': {'topic': 'solar system'}}\n"
          ]
        }
      ],
      "source": [
        "api_response = {}\n",
        "\n",
        "# Loop over multiple function calls\n",
        "for function_call in function_calls:\n",
        "    # Extract the function name\n",
        "    print(function_call)\n",
        "    for key in function_call:\n",
        "        function_name = key\n",
        "\n",
        "    # Determine which external API call to make\n",
        "    if function_name == \"search_wikipedia\":\n",
        "        result = wikipedia.search(function_call[\"search_wikipedia\"][\"query\"])\n",
        "    if function_name == \"suggest_wikipedia\":\n",
        "        result = wikipedia.suggest(function_call[\"suggest_wikipedia\"][\"query\"])\n",
        "    if function_name == \"summarize_wikipedia\":\n",
        "        result = wikipedia.summary(\n",
        "            function_call[\"summarize_wikipedia\"][\"topic\"], auto_suggest=False\n",
        "        )\n",
        "\n",
        "    # Collect all API responses\n",
        "    api_response[function_name] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdji2r7CjvYz"
      },
      "source": [
        "### Get a natural language summary\n",
        "\n",
        "Now you can return all of the API responses to Gemini so that it can generate a natural language summary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "EuaPVjGLjvYz",
        "outputId": "4ccf8dcc-382a-4193-95d4-987e8c8d5498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's some information about the Solar System:\n\nSearch results: \"Solar System\", \"Formation and evolution of the Solar System\", \"Photovoltaic system\", \"Solar System (disambiguation)\", \"List of Solar System objects by size\", \"Small Solar System body\", \"List of Solar System objects\", \"Solar System belts\", \"Passive solar building design\", \"List of natural satellites\"\n\nVariations: \"soler system\"\n\nSummary: The Solar System, formed around 4.6 billion years ago, consists of the Sun and objects orbiting it. The Sun, a G-type main-sequence star, generates energy through hydrogen fusion. Eight planets orbit the Sun: Mercury, Venus, Earth, Mars (terrestrial planets), Jupiter, Saturn (gas giants), Uranus, and Neptune (ice giants). The Solar System also contains dwarf planets (Ceres, Pluto, Eris, etc.), asteroids, comets, and more.  The Sun's influence, the solar wind, extends far beyond the planets, forming the heliosphere. The Oort cloud, a distant region, marks the Solar System's edge. Proxima Centauri, the nearest star, lies 4.25 light-years away. \n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Return the API response to Gemini\n",
        "function_response = []\n",
        "for function_name in api_response:\n",
        "    function_response.append(\n",
        "        Part.from_function_response(\n",
        "            name=function_name,\n",
        "            response={\n",
        "                \"content\": api_response[function_name],\n",
        "            },\n",
        "        )\n",
        "    )\n",
        "\n",
        "response = chat.send_message(function_response)\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDvGrmtsJY8"
      },
      "source": [
        "And you're done! You successfully made parallel function calls for a couple of different use cases. Feel free to adapt the code samples here for your own use cases and applications. Or try another notebook to continue exploring other functionality in the Gemini API.\n",
        "\n",
        "Happy parallel function calling!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "kernel": "conda-root-py",
      "name": "workbench-notebooks.m115",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}