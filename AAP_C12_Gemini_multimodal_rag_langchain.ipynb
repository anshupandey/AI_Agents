{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/AI_Agents/blob/main/AAP_C12_Gemini_multimodal_rag_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal Retrieval Augmented Generation (RAG) with Gemini, Vertex AI Vector Search, and LangChain"
      ],
      "metadata": {
        "id": "BbtmfP_ns8-Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1Q5ZYdVL4Y"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Retrieval augmented generation (RAG) has become a popular paradigm for enabling LLMs to access external data and also as a mechanism for grounding to mitigate against hallucinations.\n",
        "\n",
        "In this notebook, you will learn how to perform multimodal RAG where you will perform Q&A over a financial document filled with both text and images.\n",
        "\n",
        "### Gemini\n",
        "\n",
        "Gemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases. The Gemini API gives you access to the Gemini 1.0 Pro Vision and Gemini 1.0 Pro models.\n",
        "\n",
        "### Comparing text-based and multimodal RAG\n",
        "\n",
        "Multimodal RAG offers several advantages over text-based RAG:\n",
        "\n",
        "1. **Enhanced knowledge access:** Multimodal RAG can access and process both textual and visual information, providing a richer and more comprehensive knowledge base for the LLM.\n",
        "2. **Improved reasoning capabilities:** By incorporating visual cues, multimodal RAG can make better informed inferences across different types of data modalities.\n",
        "\n",
        "This notebook shows you how to use RAG with Vertex AI Gemini API, and [multimodal embeddings](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/multimodal-embeddings), to build a document search engine.\n",
        "\n",
        "Through hands-on examples, you will discover how to construct a multimedia-rich metadata repository of your document sources, enabling search, comparison, and reasoning across diverse information streams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQT500QqVPIb"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "This notebook provides a guide to building a document search engine using multimodal retrieval augmented generation (RAG), step by step:\n",
        "\n",
        "1. Extract and store metadata of documents containing both text and images, and generate embeddings the documents\n",
        "2. Search the metadata with text queries to find similar text or images\n",
        "3. Search the metadata with image queries to find similar images\n",
        "4. Using a text query as input, search for contextual answers using both text and images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXJpXzKrh2rJ"
      },
      "source": [
        "## Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5afkyDMSBW5"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils\n",
        "!apt-get install tesseract-ocr\n",
        "!pip install unstructured[local-inference] --quiet"
      ],
      "metadata": {
        "id": "F80YQIfBFbTS",
        "outputId": "8cca9676-d8b7-4c37-8b9a-83f8f4fcd629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kc4WxYmLSBW5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-cloud-aiplatform langchain-core langchain-google-vertexai langchain-text-splitters langchain-experimental \"unstructured[all-docs]\" pypdf pydantic lxml pillow matplotlib opencv-python tiktoken chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRvKdaPDTznN",
        "outputId": "716fa563-76fa-4106-b709-6b78292abf0a",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtsU9Bw9h2rL"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GpYEyLsOh2rL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1vKZZoEh2rL"
      },
      "source": [
        "### Define Google Cloud project information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gJqZ76rJh2rM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"maxis-poc-427906\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# For Vector Search Staging\n",
        "GCS_BUCKET = \"genai-langchain\"  # @param {type:\"string\"}\n",
        "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfWaPmaDkzBM"
      },
      "source": [
        "### Initialize the Vertex AI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D48gUW5-h2rM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=GCS_BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQwwRiniVFG"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rtMowvm-yQ97",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import uuid\n",
        "import re\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "from langchain_google_vertexai import (\n",
        "    VertexAI,\n",
        "    ChatVertexAI,\n",
        "    VertexAIEmbeddings,\n",
        "    VectorSearchVectorStore,\n",
        ")\n",
        "\n",
        "from unstructured.partition.pdf import partition_pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfzp7C9kkzBN"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7bKCQMFT7JT"
      },
      "source": [
        "#### Get documents and images from GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwbL89zcY39N",
        "outputId": "a6061798-484b-44e4-97fd-bb12ad2d98fc",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: gsutil rsync uses hashes when modification time is not available at\n",
            "both the source and destination. Your crcmod installation isn't using the\n",
            "module's C extension, so checksumming will run very slowly. If this is your\n",
            "first rsync since updating gsutil, this rsync can take significantly longer than\n",
            "usual. For help installing the extension, please see \"gsutil help crcmod\".\n",
            "\n",
            "Building synchronization state...\n",
            "Starting synchronization...\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "# Download documents and images used in this notebook\n",
        "!gsutil -m rsync -r gs://github-repo/rag/intro_multimodal_rag/ .\n",
        "print(\"Download completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps1G-cCfpibN"
      },
      "source": [
        "## Partition PDF tables, text, and images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqLsy3iZ5t-R"
      },
      "source": [
        "### The data\n",
        "\n",
        "The source data that you will use in this notebook is a modified version of [Google-10K](https://abc.xyz/assets/investor/static/pdf/20220202_alphabet_10K.pdf) which provides a comprehensive overview of the company's financial performance, business operations, management, and risk factors. As the original document is rather large, you will be using [a modified version with only 14 pages](https://storage.googleapis.com/github-repo/rag/multimodal_rag_langchain/google-10k-sample-14pages.pdf) instead. Although it's truncated, the sample document still contains text along with images such as tables, charts, and graphs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://storage.googleapis.com/github-repo/rag/multimodal_rag_langchain/google-10k-sample-14pages.pdf"
      ],
      "metadata": {
        "id": "6QGSvCY0HZeI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FxOq-Q76kzBO"
      },
      "outputs": [],
      "source": [
        "pdf_folder_path = \"/content/\" if \"google.colab\" in sys.modules else \"data/\"\n",
        "pdf_file_name = \"google-10k-sample-14pages.pdf\"\n",
        "\n",
        "# Extract images, tables, and chunk text from a PDF file.\n",
        "raw_pdf_elements = partition_pdf(\n",
        "    filename=pdf_file_name,\n",
        "    extract_images_in_pdf=True,\n",
        "    infer_table_structure=True,\n",
        "    chunking_strategy=\"by_title\",\n",
        "    max_characters=4000,\n",
        "    new_after_n_chars=3800,\n",
        "    combine_text_under_n_chars=2000,\n",
        "    image_output_dir_path=pdf_folder_path,\n",
        ")\n",
        "\n",
        "# Categorize extracted elements from a PDF into tables and texts.\n",
        "tables = []\n",
        "texts = []\n",
        "images = []\n",
        "for element in raw_pdf_elements:\n",
        "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "        tables.append(str(element))\n",
        "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
        "        texts.append(str(element))\n",
        "    elif \"unstructured.documents.elements.Image\" in str(type(element)):\n",
        "      images.append(element)\n",
        "\n",
        "# Optional: Enforce a specific token size for texts\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=10000, chunk_overlap=0\n",
        ")\n",
        "joined_texts = \" \".join(texts)\n",
        "texts_4k_token = text_splitter.split_text(joined_texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "id": "wEwYDQ4hZp0u",
        "outputId": "957fbc37-e484-4c1b-e06d-f50fa2e5a94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(joined_texts)"
      ],
      "metadata": {
        "id": "ZnCu4EW8ivTt",
        "outputId": "5753f03d-deae-433f-c63a-57738d53ddff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22053"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tables)"
      ],
      "metadata": {
        "id": "gRqAM_H3aeIR",
        "outputId": "92fe6d91-a4a6-40ac-d6e0-2d375059019a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display,Markdown\n",
        "display(Markdown(tables[0]))"
      ],
      "metadata": {
        "id": "1E6Aq-NUjpvm",
        "outputId": "3496c474-52c1-473e-d418-8a4f42a0880b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Total Number of Approxi Shares lar Value of Purchased Shares that Total Number of Total Numberof A\\ Price Ai Price Partof Publicly Yet Be Purchased A Shares Inder Purchased Purchased ClassA Share Class C Share Programs Period (in thousands) \"(in thousands) \"’ bl _*___{inthousands)\" __(in millions) _ October 1 - 31 126 1,445 $ 2,812.76 $ 2,794.72 1.571 § 26,450 November 1 - 30 289 1,393 $ 2,943.97 $ 2,956.73 1,682 $ 21,479 December 1 - 31 250 1,169 $ 2,880.79 $ 2,898.56 1,419 $ 17,371 Total 665 4,007 4,672"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements"
      ],
      "metadata": {
        "id": "FnCbbJSmknbz",
        "outputId": "1f51f168-273f-47a9-c487-2e6740ee6760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.CompositeElement at 0x7d1646060340>,\n",
              " <unstructured.documents.elements.Table at 0x7d1646060f70>,\n",
              " <unstructured.documents.elements.CompositeElement at 0x7d16460606a0>,\n",
              " <unstructured.documents.elements.CompositeElement at 0x7d1646060760>,\n",
              " <unstructured.documents.elements.CompositeElement at 0x7d1646060e20>,\n",
              " <unstructured.documents.elements.CompositeElement at 0x7d16460607c0>,\n",
              " <unstructured.documents.elements.CompositeElement at 0x7d1646061030>,\n",
              " <unstructured.documents.elements.CompositeElement at 0x7d1646061660>,\n",
              " <unstructured.documents.elements.Table at 0x7d1646061600>,\n",
              " <unstructured.documents.elements.CompositeElement at 0x7d1646060880>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "id": "cjDw8dlpj7ec",
        "outputId": "1e3884c6-d839-43b4-e5cd-9e6d9d5454d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_TOsDQU2kzBO"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gemini-1.5-flash-001\"\n",
        "\n",
        "# Generate summaries of text elements\n",
        "def generate_text_summaries(\n",
        "    texts: List[str], tables: List[str], summarize_texts: bool = False\n",
        ") -> Tuple[List, List]:\n",
        "    \"\"\"\n",
        "    Summarize text elements\n",
        "    texts: List of str\n",
        "    tables: List of str\n",
        "    summarize_texts: Bool to summarize texts\n",
        "    \"\"\"\n",
        "\n",
        "    # Prompt\n",
        "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
        "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_text)\n",
        "    empty_response = RunnableLambda(\n",
        "        lambda x: AIMessage(content=\"Error processing document\")\n",
        "    )\n",
        "    # Text summary chain\n",
        "    model = VertexAI(\n",
        "        temperature=0, model_name=MODEL_NAME, max_output_tokens=1024\n",
        "    ).with_fallbacks([empty_response])\n",
        "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
        "\n",
        "    # Initialize empty summaries\n",
        "    text_summaries = []\n",
        "    table_summaries = []\n",
        "\n",
        "    # Apply to text if texts are provided and summarization is requested\n",
        "    if texts:\n",
        "        if summarize_texts:\n",
        "            text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1})\n",
        "        else:\n",
        "            text_summaries = texts\n",
        "\n",
        "    # Apply to tables if tables are provided\n",
        "    if tables:\n",
        "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
        "\n",
        "    return text_summaries, table_summaries\n",
        "\n",
        "\n",
        "# Get text, table summaries\n",
        "text_summaries, table_summaries = generate_text_summaries(\n",
        "    texts_4k_token, tables, summarize_texts=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YKVvO1VnkzBO"
      },
      "outputs": [],
      "source": [
        "def encode_image(image_path):\n",
        "    \"\"\"Getting the base64 string\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "def image_summarize(img_base64, prompt):\n",
        "    \"\"\"Make image summary\"\"\"\n",
        "    model = ChatVertexAI(model_name=\"gemini-pro-vision\", max_output_tokens=1024)\n",
        "\n",
        "    msg = model(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"},\n",
        "                    },\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    return msg.content\n",
        "\n",
        "\n",
        "def generate_img_summaries(path):\n",
        "    \"\"\"\n",
        "    Generate summaries and base64 encoded strings for images\n",
        "    path: Path to list of .jpg files extracted by Unstructured\n",
        "    \"\"\"\n",
        "\n",
        "    # Store base64 encoded images\n",
        "    img_base64_list = []\n",
        "\n",
        "    # Store image summaries\n",
        "    image_summaries = []\n",
        "\n",
        "    # Prompt\n",
        "    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw image. \\\n",
        "    Give a concise summary of the image that is well optimized for retrieval.\n",
        "    If it's a table, extract all elements of the table.\n",
        "    If it's a graph, explain the findings in the graph.\n",
        "    Do not include any numbers that are not mentioned in the image.\n",
        "    \"\"\"\n",
        "\n",
        "    # Apply to images\n",
        "    for img_file in sorted(os.listdir(path)):\n",
        "        if img_file.endswith(\".png\"):\n",
        "            img_path = os.path.join(path, img_file)\n",
        "            base64_image = encode_image(img_path)\n",
        "            img_base64_list.append(base64_image)\n",
        "            image_summaries.append(image_summarize(base64_image, prompt))\n",
        "\n",
        "    return img_base64_list, image_summaries\n",
        "\n",
        "\n",
        "# Image summaries\n",
        "img_base64_list, image_summaries = generate_img_summaries(\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MXGRMZIkzBP"
      },
      "source": [
        "## Create & Deploy Vertex AI Vector Search Index & Endpoint\n",
        "\n",
        "Skip this step if you already have Vector Search set up.\n",
        "\n",
        "- https://console.cloud.google.com/vertex-ai/matching-engine/indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3qRRUavkzBP"
      },
      "source": [
        "- Create [`MatchingEngineIndex`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex)\n",
        "  - https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = aiplatform.MatchingEngineIndex(index_name=\"mm_rag_langchain_index\",\n",
        "                                       project=PROJECT_ID,\n",
        "                                       location=LOCATION,)\n",
        "index"
      ],
      "metadata": {
        "id": "0jTA9IWresAe",
        "outputId": "f5cc7705-47a2-42cd-a262-dd822d8beeb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgument",
          "evalue": "400 Request contains an invalid argument.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-974388b2f860>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m index = aiplatform.MatchingEngineIndex(index_name=\"mm_rag_langchain_index\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                                        \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                        location=LOCATION,)\n\u001b[1;32m      4\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/matching_engine/matching_engine_index.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index_name, project, location, credentials)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         )\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gca_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    690\u001b[0m         )\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         return getattr(self.api_client, self._getter_method)(\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_DEFAULT_RETRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1/services/index_service/client.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgument\u001b[0m: 400 Request contains an invalid argument."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Q-Us5cltkzBP",
        "outputId": "eb66d9b8-8476-4561-c064-fb036c121497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Creating MatchingEngineIndex\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Create MatchingEngineIndex backing LRO: projects/1015881047051/locations/us-central1/indexes/5654001051326480384/operations/4630938226511577088\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:MatchingEngineIndex created. Resource name: projects/1015881047051/locations/us-central1/indexes/5654001051326480384\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:To use this MatchingEngineIndex in another session:\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:index = aiplatform.MatchingEngineIndex('projects/1015881047051/locations/us-central1/indexes/5654001051326480384')\n"
          ]
        }
      ],
      "source": [
        "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings\n",
        "DIMENSIONS = 768  # Dimensions output from textembedding-gecko\n",
        "\n",
        "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=\"mm_rag_langchain_index\",\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        "    description=\"Multimodal RAG LangChain Index\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqZCywCWkzBQ"
      },
      "source": [
        "- Create [`MatchingEngineIndexEndpoint`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint)\n",
        "  - https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xR-vVUvukzBQ",
        "outputId": "1aee9465-fce2-4d8b-daed-f080bb984d68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:Creating MatchingEngineIndexEndpoint\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:Create MatchingEngineIndexEndpoint backing LRO: projects/1015881047051/locations/us-central1/indexEndpoints/4669683057769316352/operations/9128697248115326976\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:MatchingEngineIndexEndpoint created. Resource name: projects/1015881047051/locations/us-central1/indexEndpoints/4669683057769316352\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:To use this MatchingEngineIndexEndpoint in another session:\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/1015881047051/locations/us-central1/indexEndpoints/4669683057769316352')\n"
          ]
        }
      ],
      "source": [
        "DEPLOYED_INDEX_ID = \"mm_rag_langchain_index_endpoint\"\n",
        "\n",
        "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=DEPLOYED_INDEX_ID,\n",
        "    description=\"Multimodal RAG LangChain Index Endpoint\",\n",
        "    public_endpoint_enabled=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TPyoqcOkzBQ"
      },
      "source": [
        "- Deploy Index to Index Endpoint\n",
        "  - NOTE: This will take a while to run.\n",
        "  - You can stop this cell after starting it instead of waiting for deployment.\n",
        "  - You can check the status at https://console.cloud.google.com/vertex-ai/matching-engine/indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiPjTc-BkzBQ"
      },
      "outputs": [],
      "source": [
        "index_endpoint = index_endpoint.deploy_index(\n",
        "    index=index, deployed_index_id=\"mm_rag_langchain_deployed_index\"\n",
        ")\n",
        "index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEthDwxJkzBR"
      },
      "source": [
        "## Create retriever & load documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hd-v272kzBR"
      },
      "source": [
        "- Create [`VectorSearchVectorStore`](https://api.python.langchain.com/en/latest/vectorstores/langchain_google_vertexai.vectorstores.vectorstores.VectorSearchVectorStore.html) with Vector Search Index ID and Endpoint ID.\n",
        "- Use [`textembedding-gecko`](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings) as embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6CGkWxPukzBR"
      },
      "outputs": [],
      "source": [
        "# The vectorstore to use to index the summaries\n",
        "vectorstore = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=LOCATION,\n",
        "    gcs_bucket_name=GCS_BUCKET,\n",
        "    index_id=index.name,\n",
        "    endpoint_id=index_endpoint.name,\n",
        "    embedding=VertexAIEmbeddings(model_name=\"textembedding-gecko@003\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxwVcPxokzBR"
      },
      "source": [
        "- Alternatively, use Chroma for a local vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eSaolbrXkzBa"
      },
      "outputs": [],
      "source": [
        "vectorstore = Chroma(\n",
        "     collection_name=\"mm_rag_test\",\n",
        "     embedding_function=VertexAIEmbeddings(model_name=\"textembedding-gecko@003\"),)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD3LPxlVkzBb"
      },
      "source": [
        "- Create Multi-Vector Retriever using the vector store you created.\n",
        "- Since vector stores only contain the embedding and an ID, you'll also need to create a document store indexed by ID to get the original source documents after searching for embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "wH7qzrmCkzBb"
      },
      "outputs": [],
      "source": [
        "docstore = InMemoryStore()\n",
        "\n",
        "id_key = \"doc_id\"\n",
        "# Create the multi-vector retriever\n",
        "retriever_multi_vector_img = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=docstore,\n",
        "    id_key=id_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wh5WdWhkzBc"
      },
      "source": [
        "- Load data into Document Store and Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "GvJbt266kzBc",
        "outputId": "5db73b7d-0294-49cf-f077-3d45e49e1f79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4a831726-8758-48c9-ab69-48bee000a259',\n",
              " '1a661639-816f-4f30-852d-f51027af1d30',\n",
              " '96763906-cd82-430b-9d0e-18063dfb9bdd']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Raw Document Contents\n",
        "doc_contents = texts + tables + img_base64_list\n",
        "\n",
        "doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
        "summary_docs = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(text_summaries + table_summaries + image_summaries)\n",
        "]\n",
        "\n",
        "retriever_multi_vector_img.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
        "\n",
        "# If using Vertex AI Vector Search, this will take a while to complete.\n",
        "# You can cancel this cell and continue later.\n",
        "retriever_multi_vector_img.vectorstore.add_documents(summary_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1AYYKJikzBd"
      },
      "source": [
        "## Create Chain with Retriever and Gemini LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "y9BLMOnxkzBd"
      },
      "outputs": [],
      "source": [
        "def looks_like_base64(sb):\n",
        "    \"\"\"Check if the string looks like base64\"\"\"\n",
        "    return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n",
        "\n",
        "\n",
        "def is_image_data(b64data):\n",
        "    \"\"\"\n",
        "    Check if the base64 data is an image by looking at the start of the data\n",
        "    \"\"\"\n",
        "    image_signatures = {\n",
        "        b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
        "        b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
        "        b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
        "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
        "    }\n",
        "    try:\n",
        "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
        "        for sig, format in image_signatures.items():\n",
        "            if header.startswith(sig):\n",
        "                return True\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def split_image_text_types(docs):\n",
        "    \"\"\"\n",
        "    Split base64-encoded images and texts\n",
        "    \"\"\"\n",
        "    b64_images = []\n",
        "    texts = []\n",
        "    for doc in docs:\n",
        "        # Check if the document is of type Document and extract page_content if so\n",
        "        if isinstance(doc, Document):\n",
        "            doc = doc.page_content\n",
        "        if looks_like_base64(doc) and is_image_data(doc):\n",
        "            b64_images.append(doc)\n",
        "        else:\n",
        "            texts.append(doc)\n",
        "    return {\"images\": b64_images, \"texts\": texts}\n",
        "\n",
        "\n",
        "def img_prompt_func(data_dict):\n",
        "    \"\"\"\n",
        "    Join the context into a single string\n",
        "    \"\"\"\n",
        "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
        "    messages = [\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": (\n",
        "                \"You are financial analyst tasking with providing investment advice.\\n\"\n",
        "                \"You will be given a mix of text, tables, and image(s) usually of charts or graphs.\\n\"\n",
        "                \"Use this information to provide investment advice related to the user's question. \\n\"\n",
        "                f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
        "                \"Text and / or tables:\\n\"\n",
        "                f\"{formatted_texts}\"\n",
        "            ),\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Adding image(s) to the messages if present\n",
        "    if data_dict[\"context\"][\"images\"]:\n",
        "        for image in data_dict[\"context\"][\"images\"]:\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "                }\n",
        "            )\n",
        "    return [HumanMessage(content=messages)]\n",
        "\n",
        "\n",
        "# Create RAG chain\n",
        "chain_multimodal_rag = (\n",
        "    {\n",
        "        \"context\": retriever_multi_vector_img | RunnableLambda(split_image_text_types),\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | RunnableLambda(img_prompt_func)\n",
        "    | ChatVertexAI(\n",
        "        temperature=0, model_name=\"gemini-pro-vision\", max_output_tokens=1024\n",
        "    )  # Multi-modal LLM\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7opIB9jskzBd"
      },
      "source": [
        "## Process user query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "rZfhBdubkzBd"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        " - What are the critical difference between various graphs for Class A Share?\n",
        " - Which index best matches Class A share performance closely where Google is not already a part? Explain the reasoning.\n",
        " - Identify key chart patterns for Google Class A shares.\n",
        " - What is cost of revenues, operating expenses and net income for 2020. Do mention the percentage change\n",
        " - What was the effect of Covid in the 2020 financial year?\n",
        " - What are the total revenues for APAC and USA for 2021?\n",
        " - What is deferred income taxes?\n",
        " - How do you compute net income per share?\n",
        " - What drove percentage change in the consolidated revenue and cost of revenue for the year 2021 and was there any effect of Covid?\n",
        " - What is the cause of 41% increase in revenue from 2020 to 2021 and how much is dollar change?\n",
        " - provide tabular description with statistics\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjRPK3AwkzBe"
      },
      "source": [
        "### Get Retrieved documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "e5yEOmkZkzBe",
        "outputId": "a74630c0-1448-41ed-a876-1f9772c1ec02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['source: https://abc.xyz/assets/investor/static/pdf/20220202_alphabet_10K.pdf source: https://abc.xyz/assets/9a/bd/838c917c4b4ab21f94e84c3c2c65/goog-10-k-q4-2022.pdf Note: Tables and figures are converted to images for demonstration purposes.\\n\\nMARKET FOR REGISTRANT’S COMMON EQUITY, RELATED STOCKHOLDER MATTERS AND ISSUER PURCHASES OF EQUITY SECURITIES\\n\\nAs of October 2, 2015, Alphabet Inc. became the successor issuer of Google Inc. pursuant to Rule 12g-3(a) under the Exchange Act. Our Class A common stock has been listed on the Nasdaq Global Select Market under the symbol “GOOG” since August 19, 2004 and under the symbol \"GOOGL\" since April 3, 2014. Prior to August 19, 2004, there was no public market for our stock. Our Class B common stock is neither listed nor traded. Our Class C capital stock has been listed on the Nasdaq Global Select Market under the symbol “GOOG” since April 3, 2014.\\n\\nHolders of Record\\n\\nAs of December 31, 2021, there were approximately 4,907 and 1,733 stockholders of record of our Class A common stock and Class C capital stock, respectively. Because many of our shares of Class A common stock and Class C capital stock are held by brokers and other institutions on behalf of stockholders, we are unable to estimate the total number of stockholders represented by these record holders. As of December 31, 2021, there were approximately 64 stockholders of record of our Class B common stock.\\n\\nDividend Policy\\n\\nWe have never declared or paid any cash dividend on our common or capital stock. The primary use of capital continues to be to invest for the long-term growth of the business. We regularly evaluate our cash and capital structure, including the size, pace, and form of capital return to stockholders.\\n\\nIssuer Purchases of Equity Securities\\n\\nThe following table presents information with respect to Alphabet\\'s repurchases of Class A common stock and Class C capital stock during the quarter ended December 31, 2021:\\n\\nTotal Number of Approxi Shares lar Value of Purchased Shares that Total Number of Total Numberof A\\\\ Price Ai Price Partof Publicly Yet Be Purchased A Shares Inder Purchased Purchased ClassA Share Class C Share Programs Period (in thousands) \"(in thousands) \"’ bl _*___{inthousands)\" __(in millions) _ October 1 - 31 126 1,445 $ 2,812.76 $ 2,794.72 1.571 § 26,450 November 1 - 30 289 1,393 $ 2,943.97 $ 2,956.73 1,682 $ 21,479 December 1 - 31 250 1,169 $ 2,880.79 $ 2,898.56 1,419 $ 17,371 Total 665 4,007 4,672 () The repurchases are being executed from time to time, subject to general business and market conditions and other investment opportunities, through open market purchases or privately negotiated transactions, including through Rule 10b5-1 plans. The repurchase program does not have an expiration date. See Note 11 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for additional information related to share repurchases. @ Average price paid per share includes costs associated with the repurchases.', 'Executive Overview\\n\\nThe following table summarizes consolidated financial results for the years ended December 31, 2020 and 2021 unless otherwise specified (in millions, except for per share information and percentages):\\n\\nYear Ended December 31, 2020 2021 $ Change % Change Consolidated revenues $182,527 $257,637 $ 75,110 41% Change in consolidated constant currency revenues 39 % Cost of revenues $ 84,732 $ 110,939 $ 26,207 31% Operating expenses $ 56,571 $ 67,984 $ 11,413 20 % Operating income $ 41,224 $ 78,714 $ 37,490 91% Operating margin 23 % 31 % 8% Other income (expense), net $ 6858 $ 12,020 $ 5,162 75 % Net Income $ 40,269 $ 76,033 $ 35,764 89 % Diluted EPS $ 5861 $ 11220 §$ 53.59 91 % Number of Employees 135,301 156,500 21,199 16 %\\n\\n● Revenues were $257.6 billion, an increase of 41%. The increase in revenues was primarily driven by Google Services and Google Cloud. The adverse effect of COVID-19 on 2020 advertising revenues also contributed to the year-over-year growth.\\n\\n● Cost of revenues was $110.9 billion, an increase of 31%, primarily driven by increases in TAC and content acquisition costs.\\n\\n● An overall increase in data centers and other operations costs was partially offset by a reduction in depreciation expense due to the change in the estimated useful life of our servers and certain network equipment. • Operating expenses were $68.0 billion, an increase of 20%, primarily driven by headcount growth, increases in advertising and promotional expenses and charges related to legal matters.\\n\\nOther information:\\n\\n● Operating cash flow was $91.7 billion, primarily driven by revenues generated from our advertising products.\\n\\n● Share repurchases were $50.3 billion, an increase of 62%. See Note 11 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for further information.\\n\\n● Capital expenditures, which primarily reflected investments in technical infrastructure, were $24.6 billion.\\n\\n● In January 2021, we updated the useful lives of certain of our servers and network equipment, resulting in a reduction in depreciation expense of $2.6 billion recorded primarily in cost of revenues and R&D. See Note 1 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for further information.\\n\\n● Our acquisition of Fitbit closed in early January 2021, and the related revenues are included in Google other. See Note 8 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for further information.\\n\\nhad approved and declared a 20- for-one stock split in the form of a one-time special stock dividend on each share of the Company’s Class A, Class B, and Class C stock. See Note 11 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for additional information.', \"Stock Performance Graphs\\n\\nThe graph below matches Alphabet Inc. Class A's cumulative 5-year total stockholder return on common stock with the cumulative total returns of the S&P 500 index, the NASDAQ Composite index, and the RDG Internet Composite index. The graph tracks the performance of a $100 investment in our common stock and in each index (with the reinvestment of all dividends) from December 31, 2016 to December 31, 2021. The returns shown are based on historical results and are not intended to suggest future performance.\\n\\nCOMPARISON OF CUMULATIVE 5-YEAR TOTAL RETURN* ALPHABET INC. CLASS A COMMON STOCK Among Alphabet Inc., the S&P 500 Index, the NASDAQ Composite Index, and the RDG Internet Composite Index $350 $250 $150 $100 BP FSH gg g% gy oF p% gh J gph HK KML LC LS ——— Alphabet Inc. Class A ——— S&P 500 ——— RDG Internet Composite NASDAQ Composite *$100 invested on December 31, 2016 in stock or index, including reinvestment of dividends. Fiscal year ending December 31. Copyright® 2022 S&P, a division of The McGraw-Hill Companies Inc. All rights reserved.\\n\\nThe graph below matches Alphabet Inc. Class A's cumulative 5-year total stockholder return on common stock with the cumulative total returns of the S&P 500 index, the NASDAQ Composite index, and the RDG Internet Composite index. The graph tracks the performance of a $100 investment in our common stock and in each index (with the reinvestment of all dividends) from December 31, 2017 to December 31, 2022. The returns shown are based on historical results and are not intended to suggest future performance.\\n\\nCOMPARISON OF CUMULATIVE 5-YEAR TOTAL RETURN* ALPHABET INC. CLASS A COMMON STOCK Among Alphabet Inc., the S&P 500 Index, the NASDAQ Composite Index, and the RDG Internet Composite Index $400 $350 ~ $300 - $250 - $200 - $150 - $100 $50 ~ $0 “5 T T T T — — — —1— — AnD nD WD DD WD WD 1D GD GO QO GD EW aX Gr Gr GL GV GV oD BF BB ag VM MD MM MWh MMM Mh MMM Alphabet Inc. Class A —— S&P 500 = NASDAQ Composite RDG Internet Composite *$100 invested on December 31, 2017 in stock or index, including reinvestment of dividends. Copyright® 2023 S&P, a division of The McGraw-Hill Companies Inc. All rights reserved.\"]\n"
          ]
        }
      ],
      "source": [
        "# List of source documents\n",
        "docs = retriever_multi_vector_img.get_relevant_documents(query, limit=10)\n",
        "\n",
        "source_docs = split_image_text_types(docs)\n",
        "\n",
        "print(source_docs[\"texts\"])\n",
        "\n",
        "for i in source_docs[\"images\"]:\n",
        "    display(Image(base64.b64decode(i)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_docs"
      ],
      "metadata": {
        "id": "Y8Fj9v6zvuyQ",
        "outputId": "7922c5d3-1f29-457f-d933-21ac3ff7b879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'images': [],\n",
              " 'texts': ['source: https://abc.xyz/assets/investor/static/pdf/20220202_alphabet_10K.pdf source: https://abc.xyz/assets/9a/bd/838c917c4b4ab21f94e84c3c2c65/goog-10-k-q4-2022.pdf Note: Tables and figures are converted to images for demonstration purposes.\\n\\nMARKET FOR REGISTRANT’S COMMON EQUITY, RELATED STOCKHOLDER MATTERS AND ISSUER PURCHASES OF EQUITY SECURITIES\\n\\nAs of October 2, 2015, Alphabet Inc. became the successor issuer of Google Inc. pursuant to Rule 12g-3(a) under the Exchange Act. Our Class A common stock has been listed on the Nasdaq Global Select Market under the symbol “GOOG” since August 19, 2004 and under the symbol \"GOOGL\" since April 3, 2014. Prior to August 19, 2004, there was no public market for our stock. Our Class B common stock is neither listed nor traded. Our Class C capital stock has been listed on the Nasdaq Global Select Market under the symbol “GOOG” since April 3, 2014.\\n\\nHolders of Record\\n\\nAs of December 31, 2021, there were approximately 4,907 and 1,733 stockholders of record of our Class A common stock and Class C capital stock, respectively. Because many of our shares of Class A common stock and Class C capital stock are held by brokers and other institutions on behalf of stockholders, we are unable to estimate the total number of stockholders represented by these record holders. As of December 31, 2021, there were approximately 64 stockholders of record of our Class B common stock.\\n\\nDividend Policy\\n\\nWe have never declared or paid any cash dividend on our common or capital stock. The primary use of capital continues to be to invest for the long-term growth of the business. We regularly evaluate our cash and capital structure, including the size, pace, and form of capital return to stockholders.\\n\\nIssuer Purchases of Equity Securities\\n\\nThe following table presents information with respect to Alphabet\\'s repurchases of Class A common stock and Class C capital stock during the quarter ended December 31, 2021:\\n\\nTotal Number of Approxi Shares lar Value of Purchased Shares that Total Number of Total Numberof A\\\\ Price Ai Price Partof Publicly Yet Be Purchased A Shares Inder Purchased Purchased ClassA Share Class C Share Programs Period (in thousands) \"(in thousands) \"’ bl _*___{inthousands)\" __(in millions) _ October 1 - 31 126 1,445 $ 2,812.76 $ 2,794.72 1.571 § 26,450 November 1 - 30 289 1,393 $ 2,943.97 $ 2,956.73 1,682 $ 21,479 December 1 - 31 250 1,169 $ 2,880.79 $ 2,898.56 1,419 $ 17,371 Total 665 4,007 4,672 () The repurchases are being executed from time to time, subject to general business and market conditions and other investment opportunities, through open market purchases or privately negotiated transactions, including through Rule 10b5-1 plans. The repurchase program does not have an expiration date. See Note 11 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for additional information related to share repurchases. @ Average price paid per share includes costs associated with the repurchases.',\n",
              "  'Executive Overview\\n\\nThe following table summarizes consolidated financial results for the years ended December 31, 2020 and 2021 unless otherwise specified (in millions, except for per share information and percentages):\\n\\nYear Ended December 31, 2020 2021 $ Change % Change Consolidated revenues $182,527 $257,637 $ 75,110 41% Change in consolidated constant currency revenues 39 % Cost of revenues $ 84,732 $ 110,939 $ 26,207 31% Operating expenses $ 56,571 $ 67,984 $ 11,413 20 % Operating income $ 41,224 $ 78,714 $ 37,490 91% Operating margin 23 % 31 % 8% Other income (expense), net $ 6858 $ 12,020 $ 5,162 75 % Net Income $ 40,269 $ 76,033 $ 35,764 89 % Diluted EPS $ 5861 $ 11220 §$ 53.59 91 % Number of Employees 135,301 156,500 21,199 16 %\\n\\n● Revenues were $257.6 billion, an increase of 41%. The increase in revenues was primarily driven by Google Services and Google Cloud. The adverse effect of COVID-19 on 2020 advertising revenues also contributed to the year-over-year growth.\\n\\n● Cost of revenues was $110.9 billion, an increase of 31%, primarily driven by increases in TAC and content acquisition costs.\\n\\n● An overall increase in data centers and other operations costs was partially offset by a reduction in depreciation expense due to the change in the estimated useful life of our servers and certain network equipment. • Operating expenses were $68.0 billion, an increase of 20%, primarily driven by headcount growth, increases in advertising and promotional expenses and charges related to legal matters.\\n\\nOther information:\\n\\n● Operating cash flow was $91.7 billion, primarily driven by revenues generated from our advertising products.\\n\\n● Share repurchases were $50.3 billion, an increase of 62%. See Note 11 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for further information.\\n\\n● Capital expenditures, which primarily reflected investments in technical infrastructure, were $24.6 billion.\\n\\n● In January 2021, we updated the useful lives of certain of our servers and network equipment, resulting in a reduction in depreciation expense of $2.6 billion recorded primarily in cost of revenues and R&D. See Note 1 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for further information.\\n\\n● Our acquisition of Fitbit closed in early January 2021, and the related revenues are included in Google other. See Note 8 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for further information.\\n\\nhad approved and declared a 20- for-one stock split in the form of a one-time special stock dividend on each share of the Company’s Class A, Class B, and Class C stock. See Note 11 of the Notes to Consolidated Financial Statements included in Item 8 of this Annual Report on Form 10-K for additional information.',\n",
              "  \"Stock Performance Graphs\\n\\nThe graph below matches Alphabet Inc. Class A's cumulative 5-year total stockholder return on common stock with the cumulative total returns of the S&P 500 index, the NASDAQ Composite index, and the RDG Internet Composite index. The graph tracks the performance of a $100 investment in our common stock and in each index (with the reinvestment of all dividends) from December 31, 2016 to December 31, 2021. The returns shown are based on historical results and are not intended to suggest future performance.\\n\\nCOMPARISON OF CUMULATIVE 5-YEAR TOTAL RETURN* ALPHABET INC. CLASS A COMMON STOCK Among Alphabet Inc., the S&P 500 Index, the NASDAQ Composite Index, and the RDG Internet Composite Index $350 $250 $150 $100 BP FSH gg g% gy oF p% gh J gph HK KML LC LS ——— Alphabet Inc. Class A ——— S&P 500 ——— RDG Internet Composite NASDAQ Composite *$100 invested on December 31, 2016 in stock or index, including reinvestment of dividends. Fiscal year ending December 31. Copyright® 2022 S&P, a division of The McGraw-Hill Companies Inc. All rights reserved.\\n\\nThe graph below matches Alphabet Inc. Class A's cumulative 5-year total stockholder return on common stock with the cumulative total returns of the S&P 500 index, the NASDAQ Composite index, and the RDG Internet Composite index. The graph tracks the performance of a $100 investment in our common stock and in each index (with the reinvestment of all dividends) from December 31, 2017 to December 31, 2022. The returns shown are based on historical results and are not intended to suggest future performance.\\n\\nCOMPARISON OF CUMULATIVE 5-YEAR TOTAL RETURN* ALPHABET INC. CLASS A COMMON STOCK Among Alphabet Inc., the S&P 500 Index, the NASDAQ Composite Index, and the RDG Internet Composite Index $400 $350 ~ $300 - $250 - $200 - $150 - $100 $50 ~ $0 “5 T T T T — — — —1— — AnD nD WD DD WD WD 1D GD GO QO GD EW aX Gr Gr GL GV GV oD BF BB ag VM MD MM MWh MMM Mh MMM Alphabet Inc. Class A —— S&P 500 = NASDAQ Composite RDG Internet Composite *$100 invested on December 31, 2017 in stock or index, including reinvestment of dividends. Copyright® 2023 S&P, a division of The McGraw-Hill Companies Inc. All rights reserved.\"]}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-rTeciJkzBe"
      },
      "source": [
        "### Get generative response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "2BvBfSdWkzBe",
        "outputId": "69ccc4e5-e8c8-4ee5-e7c1-5a0faec5ca6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Critical Differences Between Various Graphs for Class A Share**\n\nThe provided text does not contain any information on various graphs for Class A shares. Therefore, I cannot provide the requested information.\n\n**Index that Best Matches Class A Share Performance Closely Where Google is Not Already a Part**\n\nThe provided text does not contain any information on indices that match Class A share performance closely where Google is not already a part. Therefore, I cannot provide the requested information.\n\n**Key Chart Patterns for Google Class A Shares**\n\nThe provided text does not contain any chart patterns for Google Class A shares. Therefore, I cannot provide the requested information.\n\n**Cost of Revenues, Operating Expenses, and Net Income for 2020**\n\n| **Item** | **2020** | **Percentage Change** |\n|---|---|---|\n| Cost of Revenues | $84,732 million | 31% |\n| Operating Expenses | $56,571 million | 20% |\n| Net Income | $40,269 million | 89% |\n\n**Effect of Covid in the 2020 Financial Year**\n\nThe text states that \"The adverse effect of COVID-19 on 2020 advertising revenues also contributed to the year-over-year growth.\" This suggests that the COVID-19 pandemic had a negative impact on advertising revenues in 2020, which contributed to the overall increase in revenues in 2021.\n\n**Total Revenues for APAC and USA for 2021**\n\nThe provided text does not contain information on total revenues for APAC and USA for 2021. Therefore, I cannot provide the requested information.\n\n**Deferred Income Taxes**\n\nThe provided text does not contain any information on deferred income taxes. Therefore, I cannot provide the requested information.\n\n**Computation of Net Income Per Share**\n\nThe provided text does not contain any information on how to compute net income per share. Therefore, I cannot provide the requested information.\n\n**Percentage Change in Consolidated Revenue and Cost of Revenue for 2021 and Effect of Covid**\n\n| **Item** | **Percentage Change** | **Effect of Covid** |\n|---|---|---|\n| Consolidated Revenue | 41% | The adverse effect of COVID-19 on 2020 advertising revenues contributed to the year-over-year growth. |\n| Cost of Revenue | 31% | No mention of Covid's effect on cost of revenue. |\n\n**Cause of 41% Increase in Revenue from 2020 to 2021 and Dollar Change**\n\nThe text states that \"Revenues were $257.6 billion, an increase of 41%. The increase in revenues was primarily driven by Google Services and Google Cloud.\" The dollar change in revenue from 2020 to 2021 is $75,110 million.\n\n**Tabular Description with Statistics**\n\nThe provided text does not contain any tabular description with statistics. Therefore, I cannot provide the requested information."
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "result = chain_multimodal_rag.invoke(query)\n",
        "\n",
        "Markdown(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwNrHCqbi3xi"
      },
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05jynhZnkgxn"
      },
      "source": [
        "Congratulations on making it through this multimodal RAG notebook!\n",
        "\n",
        "While multimodal RAG can be quite powerful, note that it can face some limitations:\n",
        "\n",
        "* **Data dependency:** Needs high-accuracy data from the text and visuals.\n",
        "* **Computationally demanding:** Generating embeddings from multimodal data is resource-intensive.\n",
        "* **Domain specific:** Models trained on general data may not shine in specialized fields like medicine.\n",
        "* **Black box:** Understanding how these models work can be tricky, hindering trust and adoption.\n",
        "\n",
        "\n",
        "Despite these challenges, multimodal RAG represents a significant step towards search and retrieval systems that can handle diverse, multimodal data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m116",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m116"
    },
    "kernelspec": {
      "display_name": "Python 3 (Local)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}